# -*- coding: utf-8 -*-
"""convolutional_neural_network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fKfH8wMoEsUCtxq61EEVNc2ysK9v4gha

# Convolutional Neural Network

### Importing the libraries
"""

from keras_preprocessing.image.image_data_generator import ImageDataGenerator
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from keras.backend import conv2d

tf.__version__

from google.colab import drive
drive.mount('/content/drive')

"""## Part 1 - Data Preprocessing

### Preprocessing the Training set
"""

train_datagen = ImageDataGenerator(
    rescale = 1./255,
    shear_range = 0.2,
    zoom_range = 0.2,
    horizontal_flip = True
)
training_set = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/dataset/training_set',
    target_size = (64,64),
    batch_size = 32,
    class_mode = 'binary'
)

"""### Preprocessing the Test set"""

test_datagen = ImageDataGenerator(rescale = 1./255)
test_set = test_datagen.flow_from_directory(
    '/content/drive/MyDrive/dataset/test_set',
    target_size = (64,64),
    batch_size = 32,
    class_mode = 'binary'
)

"""## Part 2 - Building the CNN

### Initialising the CNN
"""

cnn = tf.keras.models.Sequential()

"""### Step 1 - Convolution"""

cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu', input_shape = [64,64,3]))

"""### Step 2 - Pooling"""

cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))

"""### Adding a second convolutional layer"""

cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))

"""### Step 3 - Flattening"""

cnn.add(tf.keras.layers.Flatten())

"""### Step 4 - Full Connection"""

cnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))

"""### Step 5 - Output Layer"""

cnn.add(tf.keras.layers.Dense(units = 1,activation = 'sigmoid'))

"""## Part 3 - Training the CNN

### Compiling the CNN
"""

cnn.compile(optimizer = 'adam',loss = 'binary_crossentropy', metrics = ['accuracy'])

"""### Training the CNN on the Training set and evaluating it on the Test set"""

cnn.fit(x = training_set, validation_data = test_set, epochs = 25)

"""## Part 4 - Making a single prediction"""

import numpy as np
from keras.preprocessing import image
test_image = tf.keras.utils.load_img('/content/drive/MyDrive/dataset/single_prediction/cat_or_dog_1.jpg',target_size = (64,64))
test_image = tf.keras.utils.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)
result = cnn.predict(test_image/255.0) #To normalize the images
training_set.class_indices
if result[0][0] > 0.05:
  prediction = 'dog'
else:
  prediction = 'cat'
print(prediction)

"""#### This result is correct."""